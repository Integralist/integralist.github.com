<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Performance on integralist</title>
    <link>http://www.integralist.co.uk/categories/performance/</link>
    <description>Recent content in Performance on integralist</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Thu, 02 Nov 2017 13:00:00 +0100</lastBuildDate>
    
	<atom:link href="http://www.integralist.co.uk/categories/performance/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Fastly Varnish</title>
      <link>http://www.integralist.co.uk/posts/fastly-varnish/</link>
      <pubDate>Thu, 02 Nov 2017 13:00:00 +0100</pubDate>
      
      <guid>http://www.integralist.co.uk/posts/fastly-varnish/</guid>
      <description>Introduction Varnish Default VCL Fastly Custom VCL Fastly Request Flow Diagram State Variables Persisting State Hit for Pass Serving Stale Logging Conclusion  
Introduction Varnish is an open-source HTTP accelerator.
More concretely it is a web application that acts like a HTTP reverse-proxy.
You place Varnish in front of your application servers (those that are serving HTTP content) and it will cache that content for you. If you want more information on what Varnish cache can do for you, then I recommend reading through their introduction article (and watching the video linked there as well).</description>
    </item>
    
    <item>
      <title>Profiling Go</title>
      <link>http://www.integralist.co.uk/posts/profiling-go/</link>
      <pubDate>Tue, 31 Oct 2017 13:00:00 +0100</pubDate>
      
      <guid>http://www.integralist.co.uk/posts/profiling-go/</guid>
      <description>Memory Management Types of Profiling Tools Matrix Analysis Steps Base Example ReadMemStats Pprof Trace Conclusion  
Memory Management Before we dive into the techniques and tools available for profiling Go applications, we should first understand a little bit about its memory model as this can help us to understand what it is we’re seeing in relation to memory consumption.
Go’s implementation is a parallel mark-and-sweep garbage collector. In the traditional mark-and-sweep model, the garbage collector would stop the program from running (i.</description>
    </item>
    
    <item>
      <title>Profiling Python</title>
      <link>http://www.integralist.co.uk/posts/profiling-python/</link>
      <pubDate>Tue, 31 Oct 2017 13:00:00 +0100</pubDate>
      
      <guid>http://www.integralist.co.uk/posts/profiling-python/</guid>
      <description>Memory Management Types of Profiling Tools Matrix Analysis Steps Base Example Timer Built-in module: timeit Built-in module: profiler Line Profiler Basic Memory Profiler Tracemalloc PyFlame (Flame Graphs) Conclusion  
Memory Management Before we dive into the techniques and tools available for profiling Python applications, we should first understand a little bit about its memory model as this can help us to understand what it is we’re seeing in relation to memory consumption.</description>
    </item>
    
  </channel>
</rss>