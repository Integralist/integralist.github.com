<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, minimal-ui">
        <title>Big O for Beginners</title>
        <link rel="stylesheet" href="../styles/github-markdown.css">
        <link rel="stylesheet" href="../styles/prism-default.css">
        <style>
            body {
                min-width: 200px;
                max-width: 790px;
                margin: 0 auto;
                padding: 30px;
            }

            pre[class*="language-"] {
              border: 1px dashed #AAA;
              margin-bottom: 1em;
            }
        </style>
    </head>
    <body>
        <article class="markdown-body">

<h1>Big O for Beginners</h1>

<ul>
<li><a href="#1">Introduction</a></li>
<li><a href="#2">Understanding Big O</a>

<ul>
<li><a href="#3">Logarithms</a> </li>
<li><a href="#4">Logarithm Example</a> </li>
<li><a href="#5">Factorials</a> </li>
</ul></li>
<li><a href="#6">Back to Big O</a></li>
<li><a href="#7">Simple Search</a></li>
<li><a href="#8">Binary Search</a></li>
<li><a href="#9">Calculating Operation Speed</a> </li>
<li><a href="#10">Conclusion</a> </li>
</ul>

<div id="1"></div>

<h2>Introduction</h2>

<p>When you first start learning algorithms (Binary Search, Quick Sort, Breadth-first Search etc), you&#39;ll quickly realise that in order to take advantage of them, you need to know how fast they are. </p>

<p>Otherwise, when presented with a programming problem in which you want to select an algorithm to use to solve that problem, how will you know which algorithm is more efficient?</p>

<p>One way to know how fast an algorithm is, would be to use the <a href="https://en.wikipedia.org/wiki/The_Big_O">Big O</a> notation. </p>

<div id="2"></div>

<h2>Understanding Big O</h2>

<p>Big O doesn&#39;t tell you how fast in time (e.g. seconds) an algorithm is. Instead it informs you of the number of <em>operations</em>, and how those operations will grow over time.</p>

<p>Although we&#39;ll see how to calculate the speed of operations later on in this post, the primary benefit is to see &#39;at a glance&#39; the growth of operations as your data becomes larger.</p>

<blockquote>
<p>So the O in &quot;Big O&quot; means &quot;Operation&quot;</p>
</blockquote>

<p>This means in order for you to really understand Big O you&#39;re going to need to know some maths. Now, this is OK. I&#39;m genuinely terrible at maths, but you&#39;ll see as we go along that it&#39;s not as complicated as you might think.</p>

<p>Effectively there are two math concepts we need to know:</p>

<ol>
<li>Logarithms</li>
<li>Factorials</li>
</ol>

<p>You don&#39;t even need to know that much about them. Only the bare minimum is required. So let&#39;s make a start with Logarithms and then move onto Factorials afterwards. Once we understand those two concepts we can go back to Big O and start tying together some examples.</p>

<div id="3"></div>

<h3>Logarithms</h3>

<p>As I said, in order to understand Big O, you&#39;ll need to understand how <a href="https://en.wikipedia.org/wiki/Logarithm">Logarithms</a> work.</p>

<p>I&#39;m terrible at Math, but luckily the awesome book &quot;<a href="https://www.manning.com/books/grokking-algorithms">Grokking Algorithms: An Illustrated Guide</a>&quot; (which I highly recommend) helped me at least understand the basics of Logarithms; enough so that I could then go on to understand Big O.</p>

<p>In essence the Logarithm notation looks something like:</p>

<pre><code class="language-ini">Log n (—Ö)
</code></pre>

<blockquote>
<p>Note: I had used a nice <code>ùëõ</code> icon instead of <code>n</code> but on my phone I noticed it wasn&#39;t showing :-/ so I had to change it to something that wasn&#39;t a symbol.</p>
</blockquote>

<p>...where the <code>n</code> is what&#39;s called the &quot;base&quot; and <code>—Ö</code> is the number you&#39;re aiming for. But really what we&#39;re interested in is the <em>result</em> of this calculation.</p>

<div id="4"></div>

<h3>Logarithm Example</h3>

<p>Imagine we have the following Logarthim:</p>

<pre><code class="language-ini">Log5(100)
</code></pre>

<p>What this is effectively asking is:</p>

<p>&quot;how many times do I need to multiple 5 by itself in order to reach the number 100?&quot;</p>

<p>Let&#39;s find out:</p>

<pre><code class="language-ini">5*5*5 = 125
</code></pre>

<p>Looks like the result of our Logarithm would&#39;ve been <code>3</code>, because there were three <code>5</code>&#39;s used in order to get to a number that was equal or greater than <code>100</code>. </p>

<p>In this case the calculation wasn&#39;t exactly equal. By that I mean we went <em>past</em> <code>100</code> and ended up at <code>125</code>. But that&#39;s the essence of how to understand what a Logarithm is asking and how to calculate the result. </p>

<p>So we can see the calculation looks like this:</p>

<pre><code class="language-ini">Log5(100) = 3
</code></pre>

<p>The <code>3</code> is effectively the worst case number of steps involved when calculating that particular item. </p>

<p>The number <code>100</code> in this case represents the number of items we have to execute our algorithm against. So if you were using an algorithm (such as a Binary Search; demonstrated later on below) and it was running over a collection of items, then the length of the items (in the above example Logarithm) would be <code>100</code>.</p>

<p>We&#39;ll see how this is useful in measuring an algorithm&#39;s <em>speed</em> in a later section of this post. But for now let&#39;s go back to Big O...</p>

<div id="5"></div>

<h3>Factorials</h3>

<p>Factorials are one of those things that can come in handy for a number of reasons. But generally they&#39;re really useful for identifying &#39;variations&#39;.</p>

<p>Imagine you have three letters:</p>

<ul>
<li><code>A</code></li>
<li><code>B</code></li>
<li><code>C</code></li>
</ul>

<p>How many variations of these letters can you produce? So we have <code>A, B, C</code> as one variation. <code>A, C, B</code> would be another variation and then maybe <code>B, A, C</code> would be another etc. But how do you calculate how many variations there are?</p>

<p>The solution is the factorial: <code>n!</code> (where <code>n</code> is the number of items you have).</p>

<p>So in our example we had three items, so that would be written as <code>3!</code> factorial.</p>

<p>Which really means:</p>

<pre><code class="language-ini">3*2*1 = 6
</code></pre>

<p>So that&#39;s six variations you have for three items.</p>

<p>But what if you have 10 items?</p>

<pre><code class="language-ini">10*9*8*7*6*5*4*3*2*1 = 3,628,800
</code></pre>

<p>You can see that with a small number of items, the number of operations is massive. This is the total oposite of Logarithms which we looked at earlier (remember its growth of operations stayed consistently good when the collection grew). </p>

<p>Although Factorials serve a useful purpose (the example given in the book &quot;Grokking Algorithms&quot; is one called &#39;The Travelling Salesperson&#39; - which is a problem that required calculating the quickest route the saleperson can take in order to visit n number of cities) they are probably the worst performing algorithm.</p>

<p>So if you see <code>n!</code> you should be wary.</p>

<div id="6"></div>

<h2>Back to Big O</h2>

<p>So now we understand how Logarithms and Factorials work we can come back to the Big O notation and understand that it&#39;s really a simple visual wrapper around these different mathematical calculations.</p>

<pre><code class="language-ini">O(—Ö)
</code></pre>

<p>In the above snippet, <code>—Ö</code> is a calculation. </p>

<p>If we were considering Logarithms, then it would look like the following:</p>

<pre><code class="language-ini">O(Log n (—Ö))
</code></pre>

<p>If we were considering Factorials, then it would look like the following:</p>

<pre><code class="language-ini">O(n!)
</code></pre>

<p>It&#39;s important noting that you&#39;ll never see a specific calculation like <code>O(Log5(100))</code> or <code>O(3!)</code> in Big O. It&#39;ll always be an abstract version like <code>O(Log n (—Ö))</code> or <code>O(n!)</code> because Big O notation is a way of <em>talking</em> to other people and having a &#39;common language&#39;.</p>

<p>For example:</p>

<p>&quot;Hey Bob, I don&#39;t think we should use the Simple Search algorithm because it&#39;s <code>O(n)</code>. We&#39;d be much better off using a Binary Search, as that&#39;s <code>O(Log n (—Ö))</code>&quot;.</p>

<p>See how this gives us a common language. It&#39;s similar to Design Patterns. Patterns can be implemented in a variety of different ways and yet we have common language for easily identifying code that follows a certain pattern (or when we think a particular pattern might be a good solution to a design problem, we have a common language for explaining the solution to someone else without needing to actually implement it first).</p>

<p>Now my mention of &#39;Simple Search&#39; and &#39;Binary Search&#39; might not mean much to you, as you might not know how these algorithms work. So let&#39;s look at these two algorithms next and then after that you&#39;ll hopefully understand why Big O helps us understand the performance of these algorithms.</p>

<div id="7"></div>

<h2>¬†Simple Search</h2>

<p>Simple Search is probably the simplest algorithm you&#39;ll ever learn. You&#39;ll see why in just a moment... </p>

<p>Imagine you have a collection of twelve items (and these items are numbers), which are sorted/in order. You are required to locate a particular item within that collection.</p>

<p>Here is the collection:</p>

<pre><code class="language-py">[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 20, 21]
</code></pre>

<p>The Simple Search approach is to loop over the collection one item at a time and check whether the current item matches the item you&#39;re looking for.</p>

<p>So if the number you were looking for was <code>19</code>, then that means you&#39;ll first check <code>1</code>, nope that&#39;s not it. You&#39;ll then check <code>3</code>, nope that&#39;s not it either... and keep going until you reach the number you&#39;re looking for.</p>

<p>So what does this algorithm look like in Big O?</p>

<pre><code class="language-ini">O(n)
</code></pre>

<h3>What does Big O tell us?</h3>

<p>Big O is telling us that this algorithm performs in &#39;linear&#39; time. This means the number of operations increase linearly with the number of items in the collection. So in the above example, the worst case number of operations will be 12. But if the collection length was 100 items, then the worst case number of operations would be 100.</p>

<p>So in effect, the bigger the collection, the more <em>expensive</em> this algorithm becomes. With a very small collection it&#39;s fast because of its simplicity, but beyond a small collection it&#39;s a poor performing choice of algorithm. This is what Big O is telling us here.</p>

<div id="8"></div>

<h2>Binary Search</h2>

<p>Consider the same example as before, a collection of 12 items. The Binary Search algorithm is quite straight forward: you set the start and end indexes (usually zero for &#39;start&#39;, and the length of the collection for the &#39;end&#39;). </p>

<p>Now you locate the middle of the collection and check if the value you&#39;re looking for either matches or is too low/high. If it matches, then hey great you&#39;ve just reduced the number of operations by a large amount compared to the Simple Search.</p>

<p>If the middle item (our &#39;guess&#39;) is lower than the actual item we&#39;re looking for, then you reassign the value of &#39;start&#39; to be the middle index (the &#39;end&#39; stays set to the length of the collection). You&#39;ve now reduced the sliding window of items by half.</p>

<p>Alternatively if the middle item was larger than the item we&#39;re looking for, then you reassign the value &#39;end&#39; to be the middle index (the &#39;start&#39; stays set to zero). You&#39;ve again reduced the sliding window of items by half.</p>

<p>From here we &#39;rinse/repeat&#39; until the next &#39;middle of the collection&#39; selection is the item we&#39;re looking for.</p>

<p>This is a much more efficient search algorithm compared to Simple Search. </p>

<p>Let&#39;s see what this looks like in Big O notation...</p>

<pre><code class="language-ini">O(Log n (—Ö))
</code></pre>

<h3>What does Big O tell us?</h3>

<p>Big O is telling us that this algorithm works in &#39;log time&#39;, which means the performance improves as the size of the collection increases! You can tell this &#39;at a glance&#39; with Big O syntax (especially as you now know how Logarithms work). This algorithm will perform well across a wide range of collection sizes.</p>

<p>Big O in effect tells us how the operations <em>grow</em>. </p>

<p>So for this particular algorithm example, the worst case number of operations is <code>4</code>. Take a look at our earlier explanation of Logarithms if you&#39;re unsure why that is, but in a non-abstract sense this would look like: <code>O(Log2(12))</code>. We&#39;re dividing our collection in two (<code>Log2</code>) for each operation (<code>(12)</code>).</p>

<p>This is probably one of the best Big O&#39;s you&#39;ll come across as effectively the performance (and by that I mean the growth of the operations) stays consistently good as the size of the collection increases.</p>

<p>So if you have a collection of 1000 items, then that would result in (worst case) <code>10</code> operations required to locate the item you&#39;re looking for:</p>

<pre><code class="language-ini">2*2*2*2*2*2*2*2*2*2 = 1024
</code></pre>

<p>How about a collection of a million items? That would be result in (worst case) <code>20</code> (yes 20!) operations to find the item you were looking for amongst one million items. That&#39;s incredible.</p>

<div id="9"></div>

<h2>Calculating Operation Speed</h2>

<p>In order to calculate the speed of an algorithm, we need to know the worst case number of operations. This is what Big O in effect gives us (whether it be linear time, log time or factorial time). So how do we calculate the speed based on the number of operations?</p>

<p>First we need to know how many operations can be executed within one second.</p>

<p>The answer to that question is ten operations:</p>

<pre><code class="language-ini">1 second / 0.1 = 10 operations
</code></pre>

<p>We can then calculate the <em>time</em> associated with a number of operations.</p>

<p>Imagine we have the following Big O:</p>

<pre><code class="language-ini">O(Log n (—Ö))
</code></pre>

<p>If this was a collection of 16 items, then the non-abstract version would look something like:</p>

<pre><code class="language-ini">O(Log2(16))
</code></pre>

<p>We know from our earlier discussions that this would result in a worst case result of <code>4</code> operations to find the item we&#39;re searching for.</p>

<blockquote>
<p>Remember: <code>2x2x2x2 = 16</code><br>
That&#39;s <code>4</code> times we multipled <code>2</code> by itself to reach <code>16</code></p>
</blockquote>

<p>We also now know that a single operation takes <code>0.1</code> of a second.  </p>

<p>So with this in mind we can calculate the speed of <code>O(Log2(16))</code> as being: <code>0.4</code> seconds </p>

<pre><code class="language-ini">0.1 * 4 operations = 0.4
</code></pre>

<p>If we were using the Simple Search algorithm (which is <code>O(n)</code>) on a collection of 16 items, then we know that this would take <code>1.6</code> seconds to complete:</p>

<pre><code class="language-ini">0.1 * 16 operations = 1.6
</code></pre>

<div id="10"></div>

<h2>Conclusion</h2>

<p>This is a very basic introduction to the concept of Big O and Logarithms. Hopefully you&#39;ve found it useful and have a greater appreciation for what Big O offers in the way of understanding the performance of a particular algorithm (although we only really looked at two - <code>O(Log n (—Ö))</code> &amp; <code>O(n)</code> - there are many more algorithms with varying Logarithms).</p>

<p>If you notice any mistakes, then please feel free to ping me.</p>

            <hr>
            <h2>Links</h2>
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="../posts/about.html">About Me</a></li>
                <li><a href="https://github.com/integralist">GitHub</a></li>
                <li><a href="https://twitter.com/integralist">Twitter</a></li>
                <li><a href="http://www.integralist.co.uk/resume">Resume</a></li>
            </ul>
        </article>
        <script src="../scripts/prism.js"></script>
        <script>
            var _gaq=[['_setAccount','UA-33159515-1'],['_trackPageview']];
            (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
            g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
            s.parentNode.insertBefore(g,s)}(document,'script'));
        </script>
    </body>
</html>
