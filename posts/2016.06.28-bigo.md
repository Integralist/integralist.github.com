# Big O for Beginners

- [Introduction](#1)
- [Understanding Big O](#2)
  - [Logarithms](#3) 
  - [Logarithm Example](#4) 
- [Back to Big O](#5)
- [Simple Search](#6)
- [Binary Search](#7)
- [Calculating Operation Speed](#8) 
- [Conclusion](#9) 

<div id="1"></div>
## Introduction

When you first start learning algorithms (Binary Search, Quick Sort, Breadth-first Search etc), you'll quickly realise that in order to take advantage of them, you need to know how fast they are. 

Otherwise, when presented with a programming problem in which you want to select an algorithm to use to solve that problem, how will you know which algorithm is more efficient?

One way to know how fast an algorithm is, would be to use the [Big O](https://en.wikipedia.org/wiki/The_Big_O) notation. 

<div id="2"></div>
## Understanding Big O

Big O doesn't tell you how fast in time (e.g. seconds) an algorithm is. Instead it informs you of the number of _operations_, and how those operations will grow over time.

Although we'll see how to calculate the speed of operations later on in this post, the primary benefit is to see 'at a glance' the growth of operations as your data becomes larger.

> So the O in "Big O" means "Operation"

<div id="3"></div>
### Logarithms

In order to understand Big O, you'll need to understand how [Logarithms](https://en.wikipedia.org/wiki/Logarithm) work.

I'm terrible at Math, but luckily the awesome book "[Grokking Algorithms: An Illustrated Guide](https://www.manning.com/books/grokking-algorithms)" (which I highly recommend) helped me at least understand the basics of Logarithms; enough so that I could then go on to understand Big O.

In essence the Logarithm notation looks something like:

<!--language-ini-->

    Logùëõ(—Ö)

...where the `ùëõ` is what's called the "base" and `—Ö` is the number you're aiming for. But really what we're interested in is the _result_ of this calculation.

<div id="4"></div>
### Logarithm Example

Imagine we have the following Logarthim:

<!--language-ini-->

    Log5(100)

What this is effectively asking is:

"how many times do I need to multiple 5 by itself in order to reach the number 100?"

Let's find out:

<!--language-ini-->

    5*5*5 = 125

Looks like the result of our Logarithm would've been `3`, because there were three `5`'s used in order to get to a number that was equal or greater than `100`. 

In this case the calculation wasn't exactly equal. By that I mean we went _past_ `100` and ended up at `125`. But that's the essence of how to understand what a Logarithm is asking and how to calculate the result. 

So we can see the calculation looks like this:

<!--language-ini-->

    Log5(100) = 3

The `3` is effectively the worst case number of steps involved when calculating that particular item. 

The number `100` in this case represents the number of items we have to execute our algorithm against. So if you were using an algorithm (such as a Binary Search; demonstrated later on below) and it was running over a collection of items, then the length of the items (in the above example Logarithm) would be `100`.

We'll see how this is useful in measuring an algorithm's _speed_ in a later section of this post. But for now let's go back to Big O...

<div id="5"></div>
### Back to Big O

So now we understand how Logarithms work we can come back to the Big O notation and understand that it's really a simple visual wrapper around a calculation.

<!--language-ini-->

    O(—Ö)

Where `—Ö` is some calculation. Such as:

<!--language-ini-->

    O(Logùëõ(—Ö))

It's important noting that you'll never see a specific calculation like `Log5(100)`. It'll always be an abstract version like `Logùëõ(—Ö)` because Big O notation is a way of talking to other people and having a common language.

For example:

"Hey Joe, I don't think we should use the Simple Search algorithm because it's `O(ùëõ)`. We'd be better off with a Binary Search as that's `O(Logùëõ(—Ö))`".

Now at the moment that might not mean much to you as you might not know what "Simple Search" or "Binary Search" algorithms look like. So let's look at those now and then after we discuss each one you'll hopefully understand why Big O helps us understand the performance of these algorithms.

<div id="6"></div>
##¬†Simple Search

Simple Search isn't even an algorithm. You'll see what I mean in just a moment. Imagine you have a collection of twelve items (numbers), which are sorted/in order, and you wish to locate a particular item within that collection.

Here is the collection:

<!--language-py-->

    [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 20, 21]

The Simple Search approach is literally to loop over the collection one item at a time and check whether the current item matches the item you're looking for.

As I said, hardly an algorithm. But this is still something that we can wrap in Big O so we can understand the speed of this particular _algorithm_:

<!--language-ini-->

    O(ùëõ)

### What does Big O tell us?

Big O is telling us that this algorithm performs in 'linear' time. This means the number of operations increase linearly with the number of items in the collection. So in the above example, the worst case number of operations will be 12. But if the collection length was 100 items, then the worst case number of operations would be 100.

So in effect, the bigger the collection, the more _expensive_ this algorithm becomes. With a very small collection it's fast because of its simplicity, but beyond a small collection it's a poor performing choice of algorithm. This is what Big O is telling us here.

<div id="7"></div>
## Binary Search

Consider the same example as before, a collection of 12 items. The Binary Search algorithm is quite straight forward: you set the start and end indexes (usually zero for 'start', and the length of the collection for the 'end'). 

Now you locate the middle of the collection and check if the value you're looking for either matches or is too low/high. If it matches, then hey great you've just reduced the number of operations by a large amount compared to the Simple Search.

If the middle item (our 'guess') is lower than the actual item we're looking for, then you reassign the value of 'start' to be the middle index (the 'end' stays set to the length of the collection). You've now reduced the sliding window of items by half.

Alternatively if the middle item was larger than the item we're looking for, then you reassign the value 'end' to be the middle index (the 'start' stays set to zero). You've again reduced the sliding window of items by half.

From here we 'rinse/repeat' until the next 'middle of the collection' selection is the item we're looking for.

This is a much more efficient search algorithm compared to Simple Search. 

Let's see what this looks like in Big O notation...

<!--language-ini-->

    O(Logùëõ(—Ö))

### What does Big O tell us?

Big O is telling us that this algorithm works in 'log time', which means the performance improves as the size of the collection increases! You can tell this 'at a glance' with Big O syntax (especially as you now know how Logarithms work). This algorithm will perform well across a wide range of collection sizes.


Big O in effect tells us how the operations _grow_. 


So for this particular algorithm example, the worst case number of operations is `4`. Take a look at our earlier explanation of Logarithms if you're unsure why that is, but in a non-abstract sense this would look like: `O(Log2(12))`. We're dividing our collection in two (`Log2`) for each operation (`(12)`).

<div id="8"></div>
## Calculating Operation Speed

In order to calculate the speed of an algorithm, we need to know the worst case number of operations. This is what Logarithm gives us. So how do we calculate the speed based on the number of operations?

With the understanding that in one second you can execute ten operations:

<!--language-ini-->

    1/0.1 = 10

We can then calculate the _time_ associated with a number of operations.

Imagine we have the following Big O:

<!--language-ini-->

    O(Logùëõ(—Ö))


If this was a collection of 16 items, then the non-abstract version would look something like:

<!--language-ini-->

    O(Log2(16))

We know from our earlier discussions that this would result in a worst case result of `4` operations to find the item we're searching for.

> Remember: `2x2x2x2 = 16`  
> That's `4` times we multipled `2` by itself to reach `16`

We also now know that a single operation takes `0.1` of a second.  

So with this in mind we can calculate the speed of `O(Log2(16))` as being: `0.4` seconds 

<!--language-ini-->

    0.1 * 4 operations = 0.4

If we were using the Simple Search algorithm (which is `O(ùëõ)`) on a collection of 16 items, then we know that this would take `1.6` seconds to complete:

<!--language-ini-->

    0.1 * 16 operations = 1.6

<div id="9"></div>
## Conclusion

This is a very basic introduction to the concept of Big O and Logarithms. Hopefully you've found it useful and have a greater appreciation for what Big O offers in the way of understanding the performance of a particular algorithm (although we only really looked at two - `O(Logùëõ(—Ö))` & `O(ùëõ)` - there are many more algorithms with varying Logarithms).

If you notice any mistakes, then please feel free to ping me.
